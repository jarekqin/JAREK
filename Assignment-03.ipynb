{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture-03 Gradient Descent and Dymanic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week, we need complete following tasks:\n",
    "+ Re-review the course online programming; \n",
    "+ Choose 1 - 2 books which you interested and keep reading; \n",
    "+ Answer the review questions\n",
    "+ Prepare the basic requirement of our 1st project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I Review the online programming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: change loss function from $loss = \\frac{1}{n}\\sum{(y_i - \\hat(y_i))^2}$ to $loss = \\frac{1}{n}\\sum{|y_i - \\hat{y_i}|}$, and using your mathmatical knowledge to get the right partial formual. Implemen the gradient descent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, best k=-43.72870,best b=-96.57591, and loss=393.92761\n",
      "Epoch:2, best k=-29.67109,best b=58.29449, and loss=150.71026\n",
      "Epoch:5, best k=-29.79073,best b=97.69869, and loss=112.05798\n",
      "Epoch:9, best k=-12.50040,best b=71.01241, and loss=30.20528\n",
      "Epoch:27, best k=6.32430,best b=-36.84748, and loss=19.63440\n",
      "Epoch:37, best k=4.75120,best b=-21.19801, and loss=13.92868\n",
      "Epoch:137, best k=17.53175,best b=-91.43676, and loss=6.95797\n",
      "Epoch:526, best k=17.99614,best b=-88.42424, and loss=6.52792\n",
      "Epoch:594, best k=10.44585,best b=-42.57837, and loss=4.45939\n",
      "Epoch:31805, best k=9.79486,best b=-38.63609, and loss=4.43985\n",
      "-------------------------华丽的分割线-------------------------\n",
      "Epoch:999, best k=-96.00016,best b=-18.78215, and loss=644.64084\n",
      "Epoch:1999, best k=-95.00016,best b=-17.78215, and loss=637.35620\n",
      "Epoch:2999, best k=-94.00016,best b=-16.78215, and loss=630.07157\n",
      "Epoch:3999, best k=-93.00016,best b=-15.78215, and loss=622.78693\n",
      "Epoch:4999, best k=-92.00016,best b=-14.78215, and loss=615.50230\n",
      "Epoch:5999, best k=-91.00016,best b=-13.78215, and loss=608.21767\n",
      "Epoch:6999, best k=-90.00016,best b=-12.78215, and loss=600.93303\n",
      "Epoch:7999, best k=-89.00016,best b=-11.78215, and loss=593.64840\n",
      "Epoch:8999, best k=-88.00016,best b=-10.78215, and loss=586.36376\n",
      "Epoch:9999, best k=-87.00016,best b=-9.78215, and loss=579.07913\n",
      "Epoch:10999, best k=-86.00016,best b=-8.78215, and loss=571.79449\n",
      "Epoch:11999, best k=-85.00016,best b=-7.78215, and loss=564.50986\n",
      "Epoch:12999, best k=-84.00016,best b=-6.78215, and loss=557.22523\n",
      "Epoch:13999, best k=-83.00016,best b=-5.78215, and loss=549.94059\n",
      "Epoch:14999, best k=-82.00016,best b=-4.78215, and loss=542.65596\n",
      "Epoch:15999, best k=-81.00016,best b=-3.78215, and loss=535.37132\n",
      "Epoch:16999, best k=-80.00016,best b=-2.78215, and loss=528.08669\n",
      "Epoch:17999, best k=-79.00016,best b=-1.78215, and loss=520.80205\n",
      "Epoch:18999, best k=-78.00016,best b=-0.78215, and loss=513.51742\n",
      "Epoch:19999, best k=-77.00016,best b=0.21785, and loss=506.23278\n",
      "Epoch:20999, best k=-76.00016,best b=1.21785, and loss=498.94815\n",
      "Epoch:21999, best k=-75.00016,best b=2.21785, and loss=491.66352\n",
      "Epoch:22999, best k=-74.00016,best b=3.21785, and loss=484.37888\n",
      "Epoch:23999, best k=-73.00016,best b=4.21785, and loss=477.09425\n",
      "Epoch:24999, best k=-72.00016,best b=5.21785, and loss=469.80961\n",
      "Epoch:25999, best k=-71.00016,best b=6.21785, and loss=462.52498\n",
      "Epoch:26999, best k=-70.00016,best b=7.21785, and loss=455.24034\n",
      "Epoch:27999, best k=-69.00016,best b=8.21785, and loss=447.95571\n",
      "Epoch:28999, best k=-68.00016,best b=9.21785, and loss=440.67107\n",
      "Epoch:29999, best k=-67.00016,best b=10.21785, and loss=433.38644\n",
      "Epoch:30999, best k=-66.00016,best b=11.21785, and loss=426.10181\n",
      "Epoch:31999, best k=-65.00016,best b=12.21785, and loss=418.81717\n",
      "Epoch:32999, best k=-64.00016,best b=13.21785, and loss=411.53254\n",
      "Epoch:33999, best k=-63.00016,best b=14.21785, and loss=404.24790\n",
      "Epoch:34999, best k=-62.00016,best b=15.21785, and loss=396.96327\n",
      "Epoch:35999, best k=-61.00016,best b=16.21785, and loss=389.67863\n",
      "Epoch:36999, best k=-60.00016,best b=17.21785, and loss=382.39400\n",
      "Epoch:37999, best k=-59.00016,best b=18.21785, and loss=375.10937\n",
      "Epoch:38999, best k=-58.00016,best b=19.21785, and loss=367.82473\n",
      "Epoch:39999, best k=-57.00016,best b=20.21785, and loss=360.54010\n",
      "Epoch:40999, best k=-56.00016,best b=21.21785, and loss=353.25546\n",
      "Epoch:41999, best k=-55.00016,best b=22.21785, and loss=345.97083\n",
      "Epoch:42999, best k=-54.00016,best b=23.21785, and loss=338.68619\n",
      "Epoch:43999, best k=-53.00016,best b=24.21785, and loss=331.40156\n",
      "Epoch:44999, best k=-52.00016,best b=25.21785, and loss=324.11692\n",
      "Epoch:45999, best k=-51.00016,best b=26.21785, and loss=316.83229\n",
      "Epoch:46999, best k=-50.00016,best b=27.21785, and loss=309.54766\n",
      "Epoch:47999, best k=-49.00016,best b=28.21785, and loss=302.26302\n",
      "Epoch:48999, best k=-48.00016,best b=29.21785, and loss=294.97839\n",
      "Epoch:49999, best k=-47.00016,best b=30.21785, and loss=287.69375\n",
      "Epoch:50999, best k=-46.00016,best b=31.21785, and loss=280.40912\n",
      "Epoch:51999, best k=-45.00016,best b=32.21785, and loss=273.12448\n",
      "Epoch:52999, best k=-44.00016,best b=33.21785, and loss=265.83985\n",
      "Epoch:53999, best k=-43.00016,best b=34.21785, and loss=258.55522\n",
      "Epoch:54999, best k=-42.00016,best b=35.21785, and loss=251.27058\n",
      "Epoch:55999, best k=-41.00016,best b=36.21785, and loss=243.98595\n",
      "Epoch:56999, best k=-40.00016,best b=37.21785, and loss=236.70131\n",
      "Epoch:57999, best k=-39.00016,best b=38.21785, and loss=229.41668\n",
      "Epoch:58999, best k=-38.00016,best b=39.21785, and loss=222.13204\n",
      "Epoch:59999, best k=-37.00016,best b=40.21785, and loss=214.84741\n",
      "Epoch:60999, best k=-36.00016,best b=41.21785, and loss=207.56277\n",
      "Epoch:61999, best k=-35.00016,best b=42.21785, and loss=200.27814\n",
      "Epoch:62999, best k=-34.00016,best b=43.21785, and loss=192.99351\n",
      "Epoch:63999, best k=-33.00016,best b=44.21785, and loss=185.70887\n",
      "Epoch:64999, best k=-32.00016,best b=45.21785, and loss=178.42424\n",
      "Epoch:65999, best k=-31.00016,best b=46.21785, and loss=171.13960\n",
      "Epoch:66999, best k=-30.00016,best b=47.21785, and loss=163.85497\n",
      "Epoch:67999, best k=-29.00016,best b=48.21785, and loss=156.57033\n",
      "Epoch:68999, best k=-28.00016,best b=49.21785, and loss=149.28570\n",
      "Epoch:69999, best k=-27.00016,best b=50.21785, and loss=142.00106\n",
      "Epoch:70999, best k=-26.00016,best b=51.21785, and loss=134.71643\n",
      "Epoch:71999, best k=-25.00016,best b=52.21785, and loss=127.43180\n",
      "Epoch:72999, best k=-24.00016,best b=53.21785, and loss=120.14716\n",
      "Epoch:73999, best k=-23.00016,best b=54.21785, and loss=112.86253\n",
      "Epoch:74999, best k=-22.00016,best b=55.21785, and loss=105.57789\n",
      "Epoch:75999, best k=-21.00016,best b=56.21785, and loss=98.29326\n",
      "Epoch:76999, best k=-20.00016,best b=57.21785, and loss=91.00862\n",
      "Epoch:77999, best k=-19.00016,best b=58.21785, and loss=83.72399\n",
      "Epoch:78999, best k=-18.00016,best b=59.21785, and loss=76.43936\n",
      "Epoch:79999, best k=-17.00016,best b=60.21785, and loss=69.15472\n",
      "Epoch:80999, best k=-16.00016,best b=61.21785, and loss=61.87009\n",
      "Epoch:81999, best k=-15.00016,best b=62.21785, and loss=54.58545\n",
      "Epoch:82999, best k=-14.00016,best b=63.21785, and loss=47.30082\n",
      "Epoch:83999, best k=-13.00016,best b=64.21785, and loss=40.01618\n",
      "Epoch:84999, best k=-12.00016,best b=65.21785, and loss=32.78456\n",
      "Epoch:85999, best k=-11.00016,best b=66.21785, and loss=25.65167\n",
      "Epoch:86999, best k=-10.00016,best b=67.21785, and loss=18.88246\n",
      "Epoch:87999, best k=-9.00016,best b=68.21785, and loss=12.96776\n",
      "Epoch:88999, best k=-8.00016,best b=69.21785, and loss=9.73525\n",
      "Epoch:90071, best k=-7.67816,best b=68.56985, and loss=9.61448\n",
      "Epoch:91184, best k=-7.50016,best b=67.56985, and loss=9.54553\n",
      "Epoch:92267, best k=-7.35016,best b=66.56985, and loss=9.47656\n",
      "Epoch:93392, best k=-7.18016,best b=65.56985, and loss=9.40764\n",
      "Epoch:94505, best k=-7.00016,best b=64.56985, and loss=9.33968\n",
      "Epoch:95586, best k=-6.84816,best b=63.56985, and loss=9.27063\n",
      "Epoch:96657, best k=-6.69616,best b=62.56985, and loss=9.20190\n",
      "Epoch:97711, best k=-6.55616,best b=61.56985, and loss=9.13373\n",
      "Epoch:98761, best k=-6.40016,best b=60.56985, and loss=9.06549\n",
      "Epoch:99816, best k=-6.22816,best b=59.56985, and loss=8.99653\n",
      "-------------------------华丽的分割线-------------------------\n",
      "Epoch:0, best k=28.19153,best b=-75.82620, and loss=78.82609\n",
      "Epoch:4000, best k=16.04011,best b=-0.00000, and loss=78.27345\n",
      "Epoch:5000, best k=14.09387,best b=-0.00000, and loss=66.04201\n",
      "Epoch:6000, best k=12.45335,best b=-0.00000, and loss=55.73192\n",
      "Epoch:7000, best k=11.07052,best b=-0.00000, and loss=47.04137\n",
      "Epoch:8000, best k=9.90491,best b=-0.00000, and loss=39.71901\n",
      "Epoch:9000, best k=8.92240,best b=-0.00000, and loss=33.56360\n",
      "Epoch:10000, best k=8.09423,best b=-0.00000, and loss=28.38476\n",
      "Epoch:11000, best k=7.39615,best b=-0.00000, and loss=24.05026\n",
      "Epoch:12000, best k=6.80772,best b=-0.00000, and loss=20.42456\n",
      "Epoch:13000, best k=6.31173,best b=-0.00000, and loss=17.39192\n",
      "Epoch:14000, best k=5.89365,best b=-0.00000, and loss=14.93683\n",
      "Epoch:15000, best k=5.54124,best b=-0.00000, and loss=12.99307\n",
      "Epoch:16000, best k=5.24419,best b=-0.00000, and loss=11.40305\n",
      "Epoch:17000, best k=4.99380,best b=-0.00000, and loss=10.11191\n",
      "Epoch:18000, best k=4.78274,best b=-0.00000, and loss=9.09346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19000, best k=4.60483,best b=-0.00000, and loss=8.29832\n",
      "Epoch:20000, best k=4.45488,best b=-0.00000, and loss=7.68466\n",
      "Epoch:21000, best k=4.32847,best b=-0.00000, and loss=7.21137\n",
      "Epoch:22000, best k=4.22193,best b=-0.00000, and loss=6.84371\n",
      "Epoch:23000, best k=4.13212,best b=-0.00000, and loss=6.55078\n",
      "Epoch:24000, best k=4.05641,best b=-0.00000, and loss=6.32171\n",
      "Epoch:25000, best k=3.99260,best b=-0.00000, and loss=6.14462\n",
      "Epoch:26000, best k=3.93882,best b=-0.00000, and loss=6.00423\n",
      "Epoch:27000, best k=3.89348,best b=-0.00000, and loss=5.89204\n",
      "Epoch:28000, best k=3.85526,best b=-0.00000, and loss=5.80733\n",
      "Epoch:29000, best k=3.82305,best b=-0.00000, and loss=5.74343\n",
      "Epoch:30000, best k=3.79590,best b=-0.00000, and loss=5.69372\n",
      "Epoch:31000, best k=3.77301,best b=-0.00000, and loss=5.65361\n",
      "Epoch:32000, best k=3.75372,best b=-0.00000, and loss=5.62185\n",
      "Epoch:33000, best k=3.73745,best b=-0.00000, and loss=5.59665\n",
      "Epoch:34000, best k=3.72375,best b=-0.00000, and loss=5.57745\n",
      "Epoch:35000, best k=3.71219,best b=-0.00000, and loss=5.56146\n",
      "Epoch:36000, best k=3.70245,best b=-0.00000, and loss=5.54840\n",
      "Epoch:37000, best k=3.69424,best b=-0.00000, and loss=5.53817\n",
      "Epoch:38000, best k=3.68732,best b=-0.00000, and loss=5.52990\n",
      "Epoch:39000, best k=3.68149,best b=-0.00000, and loss=5.52316\n",
      "Epoch:40000, best k=3.67657,best b=-0.00000, and loss=5.51770\n",
      "Epoch:41000, best k=3.67243,best b=-0.00000, and loss=5.51317\n",
      "Epoch:42000, best k=3.66894,best b=-0.00000, and loss=5.50936\n",
      "Epoch:43000, best k=3.66599,best b=-0.00000, and loss=5.50614\n",
      "Epoch:44000, best k=3.66351,best b=-0.00000, and loss=5.50343\n",
      "Epoch:45000, best k=3.66142,best b=-0.00000, and loss=5.50119\n",
      "Epoch:46000, best k=3.65965,best b=-0.00000, and loss=5.49930\n",
      "Epoch:47000, best k=3.65817,best b=-0.00000, and loss=5.49772\n",
      "Epoch:48000, best k=3.65691,best b=-0.00000, and loss=5.49638\n",
      "Epoch:49000, best k=3.65586,best b=-0.00000, and loss=5.49528\n",
      "Epoch:50000, best k=3.65497,best b=-0.00000, and loss=5.49435\n",
      "Epoch:51000, best k=3.65422,best b=-0.00000, and loss=5.49359\n",
      "Epoch:52000, best k=3.65358,best b=-0.00000, and loss=5.49294\n",
      "Epoch:53000, best k=3.65305,best b=-0.00000, and loss=5.49240\n",
      "Epoch:54000, best k=3.65260,best b=-0.00000, and loss=5.49194\n",
      "Epoch:55000, best k=3.65222,best b=-0.00000, and loss=5.49155\n",
      "Epoch:56000, best k=3.65190,best b=-0.00000, and loss=5.49123\n",
      "Epoch:57000, best k=3.65163,best b=-0.00000, and loss=5.49095\n",
      "Epoch:58000, best k=3.65141,best b=-0.00000, and loss=5.49072\n",
      "Epoch:59000, best k=3.65122,best b=-0.00000, and loss=5.49053\n",
      "Epoch:60000, best k=3.65106,best b=-0.00000, and loss=5.49036\n",
      "Epoch:61000, best k=3.65092,best b=-0.00000, and loss=5.49022\n",
      "Epoch:62000, best k=3.65080,best b=-0.00000, and loss=5.49011\n",
      "Epoch:63000, best k=3.65071,best b=-0.00000, and loss=5.49001\n",
      "Epoch:64000, best k=3.65063,best b=-0.00000, and loss=5.48993\n",
      "Epoch:65000, best k=3.65056,best b=-0.00000, and loss=5.48986\n",
      "Epoch:66000, best k=3.65050,best b=-0.00000, and loss=5.48980\n",
      "Epoch:67000, best k=3.65045,best b=-0.00000, and loss=5.48975\n",
      "Epoch:68000, best k=3.65041,best b=-0.00000, and loss=5.48970\n",
      "Epoch:69000, best k=3.65038,best b=-0.00000, and loss=5.48967\n",
      "Epoch:70000, best k=3.65035,best b=-0.00000, and loss=5.48964\n",
      "Epoch:71000, best k=3.65032,best b=-0.00000, and loss=5.48961\n",
      "Epoch:72000, best k=3.65030,best b=-0.00000, and loss=5.48959\n",
      "Epoch:73000, best k=3.65028,best b=-0.00000, and loss=5.48958\n",
      "Epoch:74000, best k=3.65027,best b=-0.00000, and loss=5.48956\n",
      "Epoch:75000, best k=3.65026,best b=-0.00000, and loss=5.48955\n",
      "Epoch:76000, best k=3.65025,best b=-0.00000, and loss=5.48954\n",
      "Epoch:77000, best k=3.65024,best b=-0.00000, and loss=5.48953\n",
      "Epoch:78000, best k=3.65023,best b=-0.00000, and loss=5.48952\n",
      "Epoch:79000, best k=3.65022,best b=-0.00000, and loss=5.48951\n",
      "Epoch:80000, best k=3.65022,best b=-0.00000, and loss=5.48951\n",
      "Epoch:81000, best k=3.65021,best b=-0.00000, and loss=5.48950\n",
      "Epoch:82000, best k=3.65021,best b=-0.00000, and loss=5.48950\n",
      "Epoch:83000, best k=3.65021,best b=-0.00000, and loss=5.48950\n",
      "Epoch:84000, best k=3.65020,best b=-0.00000, and loss=5.48949\n",
      "Epoch:85000, best k=3.65020,best b=-0.00000, and loss=5.48949\n",
      "Epoch:86000, best k=3.65020,best b=-0.00000, and loss=5.48949\n",
      "Epoch:87000, best k=3.65020,best b=-0.00000, and loss=5.48949\n",
      "Epoch:88000, best k=3.65020,best b=-0.00000, and loss=5.48949\n",
      "Epoch:89000, best k=3.65020,best b=-0.00000, and loss=5.48949\n",
      "Epoch:90000, best k=3.65020,best b=-0.00000, and loss=5.48949\n",
      "Epoch:91000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:92000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:93000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:94000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:95000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:96000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:97000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:98000, best k=3.65019,best b=-0.00000, and loss=5.48948\n",
      "Epoch:99000, best k=3.65019,best b=-0.00000, and loss=5.48948\n"
     ]
    }
   ],
   "source": [
    "# Random Choose Method to get optimal k* and *b\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class FrameWork:\n",
    "    def __init__(self,x,y):\n",
    "        self.__y=y\n",
    "        self.__x=x\n",
    "        \n",
    "    def __price(self,r,k,b):\n",
    "        return k*r+b\n",
    "    \n",
    "    def __loss_func1(self,y,y_hat):\n",
    "        return sum((y_i-y_hat_i)**2 for y_i,y_hat_i in zip(list(y),list(y_hat)))/len(list(self.__y))\n",
    "    \n",
    "    def __loss_func2(self,y,y_hat):\n",
    "        return sum(abs(y_i-y_hat_i) for y_i,y_hat_i in zip(list(y),list(y_hat)))/len(list(self.__y))\n",
    "    \n",
    "    def calculation_random_choose(self,epoch,func_type='1'):\n",
    "        least_lost=np.inf\n",
    "        best_k=best_b=None\n",
    "        for i in range(epoch):\n",
    "            k=random.random() * 200 - 100\n",
    "            b=random.random()*200-100\n",
    "            predicted_price=[self.__price(r,k,b) for r in self.__x[:,5]]\n",
    "            \n",
    "            if func_type=='1':\n",
    "                current_loss=self.__loss_func1(self.__y,predicted_price)\n",
    "            elif func_type=='2':\n",
    "                current_loss=self.__loss_func2(self.__y,predicted_price)\n",
    "            else:\n",
    "                raise TypeError('Wrong function type!')\n",
    "                   \n",
    "            if current_loss<least_lost:\n",
    "                least_lost=current_loss\n",
    "                best_k,best_b=k,b\n",
    "                print('Epoch:%d, best k=%0.5f,best b=%0.5f, and loss=%0.5f' % (i,best_k,best_b,least_lost))\n",
    "                \n",
    "                \n",
    "    def calculation_direction(self,epoch,learning_rate=0.001,func_type='1'):\n",
    "        direction = [\n",
    "            (+1, -1), \n",
    "            (+1, +1), \n",
    "            (-1, -1), \n",
    "            (-1, +1),\n",
    "            ]\n",
    "        min_loss=float(np.inf)\n",
    "        best_k=random.random() * 200 - 100\n",
    "        best_b=random.random() * 200 - 100\n",
    "        next_direction=random.choice(direction)\n",
    "        update_time=0\n",
    "        \n",
    "        for i in range(epoch):\n",
    "    \n",
    "            k_direction, b_direction = next_direction\n",
    "    \n",
    "            current_k, current_b = best_k + k_direction * learning_rate, best_b + b_direction * learning_rate\n",
    "    \n",
    "            price_by_k_and_b = [self.__price(r, current_k, current_b) for r in self.__x[:,5]]\n",
    "\n",
    "            if func_type=='1':\n",
    "                current_loss=self.__loss_func1(self.__y,price_by_k_and_b)\n",
    "            elif func_type=='2':\n",
    "                current_loss=self.__loss_func2(self.__y,price_by_k_and_b)\n",
    "            else:\n",
    "                raise TypeError('Wrong function type!')\n",
    "    \n",
    "            if current_loss < min_loss: # performance became better\n",
    "                min_loss = current_loss\n",
    "                best_k, best_b = current_k, current_b\n",
    "        \n",
    "                next_direction = next_direction\n",
    "                update_time+=1\n",
    "                \n",
    "                if update_time%1000==0:\n",
    "                    print('Epoch:%d, best k=%0.5f,best b=%0.5f, and loss=%0.5f' % (i,best_k,best_b,min_loss))\n",
    "            else:\n",
    "                next_direction = random.choice(direction)\n",
    "                \n",
    "                \n",
    "    def calculation_gradirent(self,epoch,learning_rate=0.001,func_type='1'):\n",
    "        min_loss=float(np.inf)\n",
    "        current_k=random.random() * 200 - 100\n",
    "        current_b=random.random() * 200 - 100\n",
    "        \n",
    "        def partial_k(x,y,y_hat):\n",
    "            n=len(y)\n",
    "            gradient=0\n",
    "            for x_i,y_i,y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "                gradient+=(y_i-y_hat_i)*x_i\n",
    "                \n",
    "                return -2/n*gradient\n",
    "            \n",
    "        def partial_b(x,y,y_hat):\n",
    "            n=len(y)\n",
    "            gradient=0\n",
    "            for y_i,y_hat_i in zip(list(y),list(y_hat)):\n",
    "                gradient+=(y_i-y_hat_i)\n",
    "            return -2/n*gradient\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            predicted_price=[self.__price(r,current_k,current_b) for r in self.__x[:,5]]\n",
    "            \n",
    "            if func_type=='1':\n",
    "                current_loss=self.__loss_func1(self.__y,predicted_price)\n",
    "            elif func_type=='2':\n",
    "                current_loss=self.__loss_func2(self.__y,predicted_price)\n",
    "            else:\n",
    "                raise TypeError('Wrong function type!')\n",
    "            \n",
    "            if current_loss <min_loss:\n",
    "                min_loss=current_loss\n",
    "                best_k,best_b=current_k,current_b\n",
    "                \n",
    "                if i % 1000==0:\n",
    "                    print('Epoch:%d, best k=%0.5f,best b=%0.5f, and loss=%0.5f' % (i,best_k,best_b,min_loss))\n",
    "            k_gra=partial_k(self.__x[:,5],self.__y,predicted_price)\n",
    "            b_gra=partial_b(self.__x[:,5],self.__y,predicted_price)\n",
    "            current_k=current_k+(-1*k_gra)*learning_rate\n",
    "            current_b=current_b*(-1*b_gra)*learning_rate\n",
    "                   \n",
    "if __name__=='__main__':\n",
    "    from sklearn.datasets import load_boston\n",
    "    data = load_boston()\n",
    "    x, y = data['data'], data['target']\n",
    "    model=FrameWork(x,y)\n",
    "    model.calculation_random_choose(100000,'2')\n",
    "    print('-'*25+'华丽的分割线'+'-'*25)\n",
    "    model.calculation_direction(100000,0.001,'2')\n",
    "    print('-'*25+'华丽的分割线'+'-'*25)\n",
    "    model.calculation_gradirent(100000,0.001,'2')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Finish the Solution Parse Part of Edit-Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = {}\n",
    "#@lru_cache(maxsize=2**10)\n",
    "def edit_distance(string1, string2):\n",
    "    \n",
    "    if len(string1) == 0: return len(string2)\n",
    "    if len(string2) == 0: return len(string1)\n",
    "    \n",
    "    tail_s1 = string1[-1]\n",
    "    tail_s2 = string2[-1]\n",
    "    \n",
    "    candidates = [\n",
    "        (edit_distance(string1[:-1], string2) + 1, 'DEL {}'.format(tail_s1)),  # string 1 delete tail\n",
    "        (edit_distance(string1, string2[:-1]) + 1, 'ADD {}'.format(tail_s2)),  # string 1 add tail of string2\n",
    "    ]\n",
    "    \n",
    "    if tail_s1 == tail_s2:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 0, '')\n",
    "    else:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 1, 'SUB {} => {}'.format(tail_s1, tail_s2))\n",
    "    candidates.append(both_forward)\n",
    "    min_distance, operation = min(candidates, key=lambda x: x[0])\n",
    "    solution[(string1, string2)] = operation \n",
    "    \n",
    "    return min_distance\n",
    "\n",
    "# 解析方案\n",
    "def parse_solution(original_string,target_string, revenue_solution,original_len=1,target_len=1):\n",
    "    pass\n",
    "#     if (original_string[:original_len],target_string[:target_len] not in \\\n",
    "#                         list(set(revenue_solution.keys())):\n",
    "#         raise ('Words are not in the solution!')\n",
    "#     if target_len>len(target_string):\n",
    "#         return\n",
    "#     print(revenue_solution[(original_string[:original_len])])\n",
    "        \n",
    "\n",
    "edit_distance('ABCEF', 'ABCDEFG')\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_solution(str1,str2,solution,len1=1,len2=1):\n",
    "    if len(str1)==0 or len(str2)==0:\n",
    "        raise ValueError('str1 or str2 length cannot be 0!')\n",
    "    if len(str1)==1:\n",
    "        if len2>len(str2):\n",
    "            return\n",
    "        print(solution[(str1,str2[:len2])])\n",
    "        return parse_solution(str1,str2,solution,len1,len2+1)\n",
    "    elif len(str1)<=len(str2):\n",
    "        if len2>len(str2):\n",
    "            return\n",
    "        if str1[:len1]==str2[:len2]:\n",
    "            return parse_solution(str1,str2,solution,len1+1,len2+1)\n",
    "        else:\n",
    "            if len1<len(str1):\n",
    "                print(solution[(str1[:len1],str2[:len2])])\n",
    "                return parse_solution(str1,str2,solution,len1+1,len2+1)\n",
    "            else:\n",
    "                print(solution[(str1[:len1],str2[:len2])])\n",
    "                return parse_solution(str1,str2,solution,len1,len2+1)\n",
    "    else:\n",
    "        if len1>len(str1):\n",
    "            return\n",
    "        if str1[:len1]==str2[:len2]:\n",
    "            return parse_solution(str1,str2,solution,len1+1,len2+1)\n",
    "        else:\n",
    "            if len2<len(str2):\n",
    "                print(solution[(str1[:len1],str2[:len2])])\n",
    "                return parse_solution(str1,str2,solution,len1+1,len2+1)\n",
    "            else:\n",
    "                print(solution[(str1[:len1],str2[:len2])])\n",
    "                return parse_solution(str1,str2,solution,len1,len2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB E => D\n",
      "DEL F\n",
      "\n",
      "ADD G\n"
     ]
    }
   ],
   "source": [
    " parse_solution('ABCEF', 'ABCDEFG',solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'A'): '',\n",
       " ('A', 'AB'): 'ADD B',\n",
       " ('A', 'ABC'): 'ADD C',\n",
       " ('A', 'ABCD'): 'ADD D',\n",
       " ('A', 'ABCDE'): 'ADD E',\n",
       " ('A', 'ABCDEF'): 'ADD F',\n",
       " ('A', 'ABCDEFG'): 'ADD G',\n",
       " ('AB', 'A'): 'DEL B',\n",
       " ('AB', 'AB'): '',\n",
       " ('AB', 'ABC'): 'ADD C',\n",
       " ('AB', 'ABCD'): 'ADD D',\n",
       " ('AB', 'ABCDE'): 'ADD E',\n",
       " ('AB', 'ABCDEF'): 'ADD F',\n",
       " ('AB', 'ABCDEFG'): 'ADD G',\n",
       " ('ABC', 'A'): 'DEL C',\n",
       " ('ABC', 'AB'): 'DEL C',\n",
       " ('ABC', 'ABC'): '',\n",
       " ('ABC', 'ABCD'): 'ADD D',\n",
       " ('ABC', 'ABCDE'): 'ADD E',\n",
       " ('ABC', 'ABCDEF'): 'ADD F',\n",
       " ('ABC', 'ABCDEFG'): 'ADD G',\n",
       " ('ABCE', 'A'): 'DEL E',\n",
       " ('ABCE', 'AB'): 'DEL E',\n",
       " ('ABCE', 'ABC'): 'DEL E',\n",
       " ('ABCE', 'ABCD'): 'SUB E => D',\n",
       " ('ABCE', 'ABCDE'): '',\n",
       " ('ABCE', 'ABCDEF'): 'ADD F',\n",
       " ('ABCE', 'ABCDEFG'): 'ADD G',\n",
       " ('ABCEF', 'A'): 'DEL F',\n",
       " ('ABCEF', 'AB'): 'DEL F',\n",
       " ('ABCEF', 'ABC'): 'DEL F',\n",
       " ('ABCEF', 'ABCD'): 'DEL F',\n",
       " ('ABCEF', 'ABCDE'): 'DEL F',\n",
       " ('ABCEF', 'ABCDEF'): '',\n",
       " ('ABCEF', 'ABCDEFG'): 'ADD G'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 替代方案\n",
    "def Edit_Distance(str1, str2):\n",
    "    \"\"\"\n",
    "    计算字符串 str1 和 str2 的编辑距离\n",
    "    :param str1\n",
    "    :param str2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    matrix = [[ i + j for j in range(len(str2) + 1)] for i in range(len(str1) + 1)]\n",
    "    \n",
    "    for i in range(len(str1)):\n",
    "        matrix[i][0]=i\n",
    "    for j in range(len(str2)):\n",
    "        matrix[0][j]=j\n",
    "\n",
    "    for i in range(1, len(str1)+1):\n",
    "        for j in range(1, len(str2)+1):\n",
    "            if(str1[i-1] == str2[j-1]):\n",
    "                d = 0\n",
    "            else:\n",
    "                d = 1\n",
    "\n",
    "            matrix[i][j] = min(matrix[i-1][j]+1, matrix[i][j-1]+1, matrix[i-1][j-1]+d)\n",
    "\n",
    "    return matrix[len(str1)][len(str2)],matrix\n",
    "\n",
    "\n",
    "\n",
    "distance,matrix=Edit_Distance(\"abc\", \"bd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance,matrix=Edit_Distance('JKLSUE', 'EJFUIEL')\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Choose 1 - 2 books to keep reading: \n",
    "\n",
    "+ SICP, Structure and Interpretation of Computer Programming. \n",
    "+ Introduction to Algorithms \n",
    "+ Artificial Intelligence A Modern Approach (3rd Edition) \n",
    "+ Code Complete 2 \n",
    "+ Programming Pearls \n",
    "+ Deep Learning\n",
    "+ 黑客与画家\n",
    "+ 数学之美\n",
    "+ Fluent Python\n",
    "+ Hands on Tensorflow\n",
    "+ Conference: NIPS_ ICML_ ICLR_ ACL_ AAAI\n",
    "\n",
    "> most books you may find in our github: https://github.com/Computing-Intelligence/References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5-1: review machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we use Derivative / Gredient to fit a target function?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:Ans:In order to find global/local optimilising value if its gradient has the same direction with its derivative on parameters within a fastest way which we call it as supversied method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the words 'Gredient Descent', what's the Gredient and what's the Descent?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:Gredient is the changing rate of a variable on its forward direction, and 'descent' means that reduction of error value with recursion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. What's the advantages of the 3rd gradient descent method compared to the previous methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. It could help to find global/local minminum value within fastest speed and correct direction.\n",
    "2. Cooperating with learning_rate to control whole calculating procedure in order to find a most accurate result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the simple words to describe: What's the machine leanring.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Using statical and mathematical model/theory to simulate human being's thinking in order to resolve complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Answer following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we need dynamic programming? What's the difference of dynamic programming and previous talked `search` problme? \n",
    "\n",
    "Answer:\n",
    "\n",
    "As DP method can store sub-question solutions during its calculating procudures which would be useful to find detailed sequence as a global result for every step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Why do we still need dynamic programming? Why not we train a machine learning to fit a function which could get the `right` answer based on inputs?\n",
    "\n",
    "Answer:\n",
    "\n",
    "In the statistic section, we have a quiet famous role that Occam's Razor. As some of machine learning methods need a large amount of time where they will have to cost much more time than using simple algorithms. Dynamic programming is one of simple ones. We therefore mainly rely on this method to resolve some problems with quick way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Can you catch up at least 3 problems which could solved by Dynamic Programming? \n",
    "\n",
    "Answer:\n",
    "1. The question that is recursively solved by sub-questions need more memories on PC;\n",
    "2. If we do not set a stop condition, we then could see a cycle forever;\n",
    "3. Speey sometimes would be slowly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Can you catch up at least 3 problems wich could sloved by Edit Distance? \n",
    "\n",
    "Answer:\n",
    "1. Map searching for destination with different starting points;\n",
    "2. Predicting next word or set of words by previous specific setence or words;\n",
    "3. Gene detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Please summarize the three main features of Dynamic Programming, and make a concise explain for each feature. \n",
    "\n",
    "Answer:\n",
    "1. Parent problem can be solved by different sub-question-->It means that we can use reversion method;\n",
    "2. Every result could be a minimum local value-->Make sure that every step could get optimum value;\n",
    "3. Every sub-question will be calculated one by one--> Result of last sub-question would be whole question's answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What's the disadvantages of Dynamic Programming? (You may need search by yourself in Internet)\n",
    "\n",
    "Answer:\n",
    "1. There is no standard models we can simulate;\n",
    "2. It could see Dimension explosion when sequence is quiet large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 Preparation of Project-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using python Flask or Bottle to finish your first simple web app:\n",
    "> https://bottlepy.org/\n",
    "\n",
    "2. Learn what's the SQL, and try some simple SQL operations:\n",
    "> https://www.w3schools.com/sql/sql_intro.asp\n",
    "\n",
    "3. Learn what's the HTML ( *ONLY* need to know the basic things)\n",
    "> https://getbootstrap.com/; https://www.w3schools.com/html/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optinal) Finish the k-person-salesman problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "个人想法:\n",
    "是否可以根据有向图拓扑进行逐个搜索(全局搜索),根据点之间的距离搜寻点和点之间的最短距离,然后用动态规划来记录访问过的点和其拓扑节点距离.\n",
    "如果访问过则删去,没访问过就即使记录.直到把每一个点都遍历.(代码有难度...尝试ing...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = [random.randint(-100, 100) for _ in range(20)]\n",
    "longitude = [random.randint(-100, 100) for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbd6bbdcb00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(latitudes, longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个初始点 𝑃, 已经有𝑘个车辆，如何从该点出发，经这 k 个车辆经过所有的点全部一次，而且所走过的路程最短?\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_p = (-50, 10)\n",
    "chosen_p2 = (1, 30)\n",
    "chosen_p3 = (99, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbd6bb1a4e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(latitudes, longitude)\n",
    "plt.scatter([chosen_p[0]], [chosen_p[1]], color='r')\n",
    "plt.scatter([chosen_p2[0]], [chosen_p2[1]], color='r')\n",
    "plt.scatter([chosen_p3[0]], [chosen_p3[1]], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
